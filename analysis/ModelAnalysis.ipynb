{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "\n",
    "# Ensure the parent directory is in the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(settings.DATABASE_PATH) as conn:\n",
    "    df = pd.read_sql(\n",
    "        f\"\"\"\n",
    "            SELECT * FROM Matches\n",
    "        \"\"\",\n",
    "        conn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"score\"]).copy()\n",
    "df[\"home_score\"] = df[\"score\"].str.split(\":\").str[0].astype(int)\n",
    "df[\"away_score\"] = df[\"score\"].str.split(\":\").str[1].astype(int)\n",
    "df[\"home_win\"] = (df[\"home_score\"] > df[\"away_score\"]).astype(int)\n",
    "df[\"away_win\"] = (df[\"home_score\"] < df[\"away_score\"]).astype(int)\n",
    "df[\"tie\"] = (df[\"home_score\"] == df[\"away_score\"]).astype(int)\n",
    "df[\"difference_score\"] = abs(df[\"home_score\"] - df[\"away_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_date(row):\n",
    "    \"\"\"\n",
    "    Adjust the date by adding the correct century based on the season.\n",
    "    If the date\"s year is less than the season\"s end year, use the start year,\n",
    "    otherwise use the end year of the season.\n",
    "\n",
    "    :param row: A row from the DataFrame containing \"date\" and \"season\".\n",
    "    :return: Adjusted date string in the format DD/MM/YYYY.\n",
    "    \"\"\"\n",
    "    start_year = int(row[\"season\"].split(\"-\")[0])\n",
    "    end_year = int(row[\"season\"].split(\"-\")[1])\n",
    "    date_year = int(row[\"date\"].split(\"/\")[-1])\n",
    "\n",
    "    if date_year == start_year % 100:\n",
    "        return row[\"date\"][:-2] + str(start_year)\n",
    "    else:\n",
    "        return row[\"date\"][:-2] + str(end_year)\n",
    "\n",
    "\n",
    "df[\"date\"] = df.apply(adjust_date, axis=1)\n",
    "df = df.dropna(subset=[\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"score\"])\n",
    "df[\"season\"] = df[\"season\"].str.split(\"-\").str[0].astype(int)\n",
    "\n",
    "conditions = [(df[\"home_win\"] == 1), (df[\"tie\"] == 1), (df[\"away_win\"] == 1)]\n",
    "\n",
    "choices = [1, 0, -1]\n",
    "\n",
    "df[\"result\"] = np.select(conditions, choices, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_results(df, max_matchday=None):\n",
    "    \"\"\"\n",
    "    Calculates team results up to a specific matchday.\n",
    "    Has been modified to include just the necessary columns for the model.\n",
    "\n",
    "    :param df: DataFrame with match data\n",
    "    :param max_matchday: Only consider matches up to this matchday (exclusive)\n",
    "    :return: DataFrame with team points\n",
    "    \"\"\"\n",
    "    if max_matchday is not None:\n",
    "        df = df[df[\"matchday\"] < max_matchday].copy()\n",
    "\n",
    "    df_results = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                df.groupby([\"season\", \"home_team\"])\n",
    "                .agg(\n",
    "                    W=(\"home_win\", \"sum\"),\n",
    "                    L=(\"away_win\", \"sum\"),\n",
    "                    T=(\"tie\", \"sum\"),\n",
    "                )\n",
    "                .reset_index()\n",
    "                .rename(columns={\"home_team\": \"team\"}),\n",
    "                df.groupby([\"season\", \"away_team\"])\n",
    "                .agg(\n",
    "                    W=(\"away_win\", \"sum\"),\n",
    "                    L=(\"home_win\", \"sum\"),\n",
    "                    T=(\"tie\", \"sum\"),\n",
    "                )\n",
    "                .reset_index()\n",
    "                .rename(columns={\"away_team\": \"team\"}),\n",
    "            ]\n",
    "        )\n",
    "        .groupby([\"season\", \"team\"])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df_results[\"points\"] = df_results[\"W\"] * 3 + df_results[\"T\"]\n",
    "\n",
    "    df_results = df_results.sort_values(\n",
    "        by=[\"season\", \"points\"],\n",
    "        ascending=[False, False],\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    df_results[\"rank\"] = (\n",
    "        df_results.groupby([\"season\"])[\"points\"]\n",
    "        .rank(\"first\", ascending=False)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    df_results = df_results[\n",
    "        [\n",
    "            \"season\",\n",
    "            \"team\",\n",
    "            \"points\",\n",
    "        ]\n",
    "    ]\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_confrontations(df, team1, team2):\n",
    "    \"\"\"\n",
    "    Returns the confrontations between two teams\n",
    "\n",
    "    :param df: DataFrame with match data\n",
    "    :param team1: First team\n",
    "    :param team2: Second team\n",
    "    :return: DataFrame with confrontations between the two teams\n",
    "    \"\"\"\n",
    "    df_confrontations = df.loc[\n",
    "        ((df[\"home_team\"] == team1) | (df[\"away_team\"] == team1))\n",
    "        & ((df[\"home_team\"] == team2) | (df[\"away_team\"] == team2))\n",
    "    ]\n",
    "\n",
    "    return df_confrontations\n",
    "\n",
    "\n",
    "def won_games(df, team: str):\n",
    "    \"\"\"\n",
    "    Returns those winning games for a given team\n",
    "\n",
    "    :param df: DataFrame with match data\n",
    "    :param team: Team name\n",
    "    :return: DataFrame with winning games for the team\n",
    "    \"\"\"\n",
    "    home_wins = (df[\"home_team\"] == team) & (df[\"home_win\"] == 1)\n",
    "    away_wins = (df[\"away_team\"] == team) & (df[\"away_win\"] == 1)\n",
    "    return df[home_wins | away_wins]\n",
    "\n",
    "\n",
    "def lost_games(df, team: str):\n",
    "    \"\"\"\n",
    "    Returns those winning games for a given team\n",
    "\n",
    "    :param df: DataFrame with match data\n",
    "    :param team: Team name\n",
    "    :return: DataFrame with winning games for the team\n",
    "    \"\"\"\n",
    "    home_lost = (df[\"home_team\"] == team) & (df[\"home_win\"] == 0)\n",
    "    away_lost = (df[\"away_team\"] == team) & (df[\"away_win\"] == 0)\n",
    "    tie_games = (df[\"home_team\"] == team) & (df[\"tie\"] == 1) | (\n",
    "        df[\"away_team\"] == team\n",
    "    ) & (df[\"tie\"] == 1)\n",
    "\n",
    "    return df[(home_lost | away_lost) & ~tie_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_lost_index(row, df_conf_dict):\n",
    "    \"\"\"\n",
    "    Calculates win and loss punctuation between two teams for the row's season,\n",
    "    using a precomputed dictionary of relevant confrontations for each season.\n",
    "\n",
    "    This function returns a victory and lose punctuation between 2 teams.\n",
    "    It is given by 1 / ((currentseason - season)^2 + 1)\n",
    "    This function has a maximum in currentseason and it deacreses as season increase\n",
    "    Giving more importance to recent matches.\n",
    "    It is symmetric for both teams, so win_team1 = lost_team2.\n",
    "\n",
    "    :param row: A row from the DataFrame containing \"season\", \"home_team\" and \"away_team\".\n",
    "    :param df_conf_dict: A dictionary containing relevant confrontations for each season.\n",
    "    :return: A tuple with the win and loss punctuation for the row's season.\n",
    "    \"\"\"\n",
    "    season = row[\"season\"]\n",
    "    team1 = row[\"home_team\"]\n",
    "    team2 = row[\"away_team\"]\n",
    "\n",
    "    df_conf = df_conf_dict.get((team1, team2), pd.DataFrame())\n",
    "\n",
    "    df_won = won_games(df_conf, team1)\n",
    "    if not df_won.empty:\n",
    "        df_won[\"win_punct\"] = 1 / ((season - df_won[\"season\"].astype(int)) ** 2 + 1)\n",
    "        win_punct = df_won[\"win_punct\"].sum()\n",
    "    else:\n",
    "        win_punct = 0\n",
    "\n",
    "    df_lost = lost_games(df_conf, team1)\n",
    "    if not df_lost.empty:\n",
    "        df_lost[\"lost_punct\"] = 1 / ((season - df_lost[\"season\"].astype(int)) ** 2 + 1)\n",
    "        lost_punct = df_lost[\"lost_punct\"].sum()\n",
    "    else:\n",
    "        lost_punct = 0\n",
    "\n",
    "    return win_punct, lost_punct\n",
    "\n",
    "\n",
    "def inform_win_lost_index(df, df_calculate, depth=20):\n",
    "    \"\"\"\n",
    "    Adds win and loss punctuation to the DataFrame for each row's season.\n",
    "\n",
    "    :param df: DataFrame containing match data for all teams.\n",
    "    :param df_calculate: DataFrame containing the matches to calculate the win and loss punctuation.\n",
    "    :return: DataFrame with the win and loss punctuation for each row's season.\n",
    "    \"\"\"\n",
    "    max_season = df_calculate[\"season\"].max()\n",
    "    df_recent = df[df[\"season\"] >= (max_season - depth)].copy()\n",
    "\n",
    "    teams = df_calculate[[\"home_team\", \"away_team\"]].drop_duplicates()\n",
    "    df_conf_dict = {\n",
    "        (team1, team2): team_confrontations(df_recent, team1, team2)\n",
    "        for team1, team2 in zip(teams[\"home_team\"], teams[\"away_team\"])\n",
    "    }\n",
    "\n",
    "    df_calculate[[\"win_punct\", \"lost_punct\"]] = df_calculate.apply(\n",
    "        lambda row: win_lost_index(row, df_conf_dict), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    return df_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_points(row, df_results_dict):\n",
    "    \"\"\"\n",
    "    Calculates the difference in points between home and away teams\n",
    "    considering only matches before the current matchday.\n",
    "\n",
    "    :param row: DataFrame row with home_team, away_team, season, and matchday\n",
    "    :param df_results_dict: Dictionary of {season: {matchday: results_df}}\n",
    "    :return: Point difference between home and away team\n",
    "    \"\"\"\n",
    "    season = row[\"season\"]\n",
    "    matchday = row[\"matchday\"]\n",
    "\n",
    "    results_key = (season, matchday)\n",
    "    if results_key not in df_results_dict:\n",
    "        return 0\n",
    "\n",
    "    results_df = df_results_dict[results_key]\n",
    "\n",
    "    try:\n",
    "        home_team_points = results_df.loc[\n",
    "            results_df[\"team\"] == row[\"home_team\"], \"points\"\n",
    "        ].iloc[0]\n",
    "        away_team_points = results_df.loc[\n",
    "            results_df[\"team\"] == row[\"away_team\"], \"points\"\n",
    "        ].iloc[0]\n",
    "        return home_team_points - away_team_points\n",
    "    except (KeyError, IndexError):\n",
    "        return 0\n",
    "\n",
    "\n",
    "def inform_relatives_points(df, df_calculate):\n",
    "    \"\"\"\n",
    "    Calculates relative points for each match considering only previous matchdays.\n",
    "\n",
    "    :param df: Complete DataFrame with all matches\n",
    "    :param df_calculate: DataFrame with matches to calculate features for\n",
    "    :return: DataFrame with added relative points features\n",
    "    \"\"\"\n",
    "    df_results_dict = {}\n",
    "\n",
    "    for season in df_calculate[\"season\"].unique():\n",
    "        season_data = df[df[\"season\"] == season].copy()\n",
    "\n",
    "        for matchday in df_calculate[df_calculate[\"season\"] == season][\n",
    "            \"matchday\"\n",
    "        ].unique():\n",
    "            results = calculate_team_results(season_data, max_matchday=matchday)\n",
    "            df_results_dict[(season, matchday)] = results\n",
    "\n",
    "    df_calculate[\"points_relative\"] = df_calculate.apply(\n",
    "        lambda row: difference_points(row, df_results_dict), axis=1\n",
    "    )\n",
    "\n",
    "    df_calculate[\"points_relative_index\"] = df_calculate.apply(\n",
    "        lambda row: row[\"points_relative\"]\n",
    "        * (row[\"matchday\"] ** 2 / (row[\"matchday\"] ** 2 + 38))\n",
    "        if row[\"matchday\"] > 0\n",
    "        else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return df_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(df):\n",
    "    \"\"\"\n",
    "    Precalculates results for all matches.\n",
    "\n",
    "    :param df: DataFrame with match data\n",
    "    :return: DataFrame with results for all matches\n",
    "    \"\"\"\n",
    "    home_results = df[[\"matchday\", \"season\", \"home_team\", \"home_win\", \"tie\"]].copy()\n",
    "    home_results[\"team\"] = home_results[\"home_team\"]\n",
    "    home_results[\"Result\"] = np.where(\n",
    "        home_results[\"tie\"] == 1, \"T\", np.where(home_results[\"home_win\"] == 1, \"W\", \"L\")\n",
    "    )\n",
    "\n",
    "    away_results = df[[\"matchday\", \"season\", \"away_team\", \"away_win\", \"tie\"]].copy()\n",
    "    away_results[\"team\"] = away_results[\"away_team\"]\n",
    "    away_results[\"Result\"] = np.where(\n",
    "        away_results[\"tie\"] == 1, \"T\", np.where(away_results[\"away_win\"] == 1, \"W\", \"L\")\n",
    "    )\n",
    "\n",
    "    all_results = pd.concat(\n",
    "        [\n",
    "            home_results[[\"matchday\", \"season\", \"team\", \"Result\"]],\n",
    "            away_results[[\"matchday\", \"season\", \"team\", \"Result\"]],\n",
    "        ]\n",
    "    ).sort_values([\"team\", \"season\", \"matchday\"], ascending=[True, True, False])\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def get_last_5_results(all_results, matchday, team, season):\n",
    "    \"\"\"\n",
    "    Gets all available results up to 5 for a team in a season.\n",
    "\n",
    "    :param all_results: DataFrame with all results\n",
    "    :param matchday: Current matchday\n",
    "    :param team: Team name\n",
    "    :param season: Season\n",
    "    :return: Tuple with the last 5 results and the number of matches\n",
    "    \"\"\"\n",
    "    mask = (\n",
    "        (all_results[\"team\"] == team)\n",
    "        & (all_results[\"season\"] == season)\n",
    "        & (all_results[\"matchday\"] < matchday)\n",
    "    )\n",
    "\n",
    "    results = all_results[mask][\"Result\"].head(5).tolist()\n",
    "    return results, len(results)\n",
    "\n",
    "\n",
    "def convert_results_to_points(results_tuple):\n",
    "    \"\"\"\n",
    "    Converts results to points with correction factor for fewer than 5 matches.\n",
    "    The correction factor is 5 / num_matches.\n",
    "\n",
    "    :param results_tuple: Tuple with results and number of matches\n",
    "    :return: Corrected points\n",
    "    \"\"\"\n",
    "    results, num_matches = results_tuple\n",
    "    if num_matches == 0:\n",
    "        return 0\n",
    "\n",
    "    points_map = {\"W\": 3, \"L\": 0, \"T\": 1}\n",
    "    total_points = sum(points_map[result] for result in results)\n",
    "\n",
    "    correction_factor = 5 / num_matches\n",
    "    corrected_points = total_points * correction_factor\n",
    "\n",
    "    return round(corrected_points, 2)\n",
    "\n",
    "\n",
    "def last5index(df, df_predict):\n",
    "    \"\"\"\n",
    "    Calculates the last 5 matches index for all teams with correction for fewer matches.\n",
    "\n",
    "    :param df: DataFrame with all matches\n",
    "    :param df_predict: DataFrame with matches to calculate features for\n",
    "    :return: DataFrame with added last 5 matches index features\n",
    "    \"\"\"\n",
    "    # df_calculate has the last 5 matches results so takes the same season as df_predict and the matchday is less than the matchday of the match to predict\n",
    "    df_calculate = df.loc[\n",
    "        (df[\"season\"] == df_predict[\"season\"].max())\n",
    "        & (df[\"matchday\"] < df_predict[\"matchday\"].max())\n",
    "        & (df[\"matchday\"] >= df_predict[\"matchday\"].max() - 5)\n",
    "    ].copy()\n",
    "\n",
    "    all_results = calculate_results(df_calculate)\n",
    "\n",
    "    df_predict[\"last5_home\"] = df_predict.apply(\n",
    "        lambda row: get_last_5_results(\n",
    "            all_results, row[\"matchday\"], row[\"home_team\"], row[\"season\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_predict[\"last5_away\"] = df_predict.apply(\n",
    "        lambda row: get_last_5_results(\n",
    "            all_results, row[\"matchday\"], row[\"away_team\"], row[\"season\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    df_predict[\"last5_home\"] = df_predict[\"last5_home\"].apply(convert_results_to_points)\n",
    "    df_predict[\"last5_away\"] = df_predict[\"last5_away\"].apply(convert_results_to_points)\n",
    "\n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_season_position(df, df_predict):\n",
    "    \"\"\"\n",
    "    Adds the last season points in a new column.\n",
    "    If a team was not in the last season, the average of the last season minus 20 is used.\n",
    "\n",
    "    :param df: DataFrame with all matches\n",
    "    :param df_predict: DataFrame with matches to calculate features for\n",
    "    :return: DataFrame with added last season points\n",
    "    \"\"\"\n",
    "    df_calculate = df.loc[(df[\"season\"] == df_predict[\"season\"].max() - 1)].copy()\n",
    "    df_results = calculate_team_results(df_calculate)\n",
    "\n",
    "    df_predict[\"last_season_points_home\"] = df_predict.apply(\n",
    "        lambda row: df_results.loc[\n",
    "            df_results[\"team\"] == row[\"home_team\"], \"points\"\n",
    "        ].iloc[0]\n",
    "        if row[\"home_team\"] in df_results[\"team\"].values\n",
    "        else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_predict[\"last_season_points_away\"] = df_predict.apply(\n",
    "        lambda row: df_results.loc[\n",
    "            df_results[\"team\"] == row[\"away_team\"], \"points\"\n",
    "        ].iloc[0]\n",
    "        if row[\"away_team\"] in df_results[\"team\"].values\n",
    "        else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Improvement, calcualte mean of the teams that ascend to the league\n",
    "    df_predict[\"last_season_points_home\"] = df_predict[\n",
    "        \"last_season_points_home\"\n",
    "    ].replace(0, df_results[\"points\"].mean() - 20)\n",
    "    df_predict[\"last_season_points_away\"] = df_predict[\n",
    "        \"last_season_points_away\"\n",
    "    ].replace(0, df_results[\"points\"].mean() - 20)\n",
    "    return df_predict\n",
    "\n",
    "# # example of usage last_season_position\n",
    "# train_season = 2015\n",
    "# depth = 20  # Number of seasons to consider for training\n",
    "# df_test = df.loc[\n",
    "#     (df[\"season\"] > (train_season - depth)) & (df[\"season\"] <= train_season)\n",
    "# ].copy()\n",
    "# df_test = last_season_position(df, df_test)\n",
    "# display(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data that will be used for training\n",
    "train_season = 2015\n",
    "depth = 20  # Number of seasons to consider for training\n",
    "\n",
    "df_train = df.loc[\n",
    "    (df[\"season\"] > (train_season - depth)) & (df[\"season\"] <= train_season)\n",
    "].copy()\n",
    "\n",
    "df_train = inform_relatives_points(df, df_train)\n",
    "print(\"Relative points calculated\")\n",
    "df_train = inform_win_lost_index(df, df_train)\n",
    "print(\"Win and loss index calculated\")\n",
    "df_train = last5index(df, df_train)\n",
    "print(\"Last 5 index calculated\")\n",
    "df_train = last_season_position(df, df_train)\n",
    "print(\"Last season position calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"win_punct\",\n",
    "    \"lost_punct\",\n",
    "    \"points_relative_index\",\n",
    "    \"last5_home\",\n",
    "    \"last5_away\",\n",
    "    \"last_season_points_home\",\n",
    "    \"last_season_points_away\",\n",
    "]\n",
    "target = \"result\"\n",
    "\n",
    "x_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=40\n",
    ")\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = clf.predict(x_val)\n",
    "validation_accuracy = (y_val_pred == y_val).mean()\n",
    "print(f\"Validation Accuracy: {validation_accuracy:.2%}\")\n",
    "\n",
    "# Save the model\n",
    "model_name = \"model2-11-20s-7f.pkl\"\n",
    "joblib.dump(clf, f\"../models/{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(feature_importance, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Creates an enhanced feature importance visualization\n",
    "\n",
    "    :param feature_importance: DataFrame with feature importance values\n",
    "    :param figsize: Figure size\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    bars = plt.barh(\n",
    "        feature_importance[\"feature\"],\n",
    "        feature_importance[\"importance\"],\n",
    "        color=\"skyblue\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(\n",
    "            width,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{width:.5f}\",\n",
    "            ha=\"left\",\n",
    "            va=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Feature Importance Score\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(\"Feature Importance Analysis\", pad=20)\n",
    "\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_analysis(y_true, y_pred, clf, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Creates a comprehensive confusion matrix analysis with metrics\n",
    "\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :param clf: Classifier used for prediction\n",
    "    :param figsize: Figure size\n",
    "    \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    classes = clf.classes_\n",
    "    class_names = [\n",
    "        f\"Class {c}\" if isinstance(c, (int, np.integer)) else str(c) for c in classes\n",
    "    ]\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        ax=ax1,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Predicted\")\n",
    "    ax1.set_ylabel(\"Actual\")\n",
    "    ax1.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    metrics_data = pd.DataFrame(\n",
    "        {\"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1}, index=class_names\n",
    "    )\n",
    "\n",
    "    sns.heatmap(metrics_data, annot=True, fmt=\".3f\", cmap=\"RdYlGn\", ax=ax2)\n",
    "    ax2.set_title(\"Performance Metrics by Class\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "\n",
    "def analyze_model_performance(feature_importance, y_true, y_pred, clf):\n",
    "    \"\"\"\n",
    "    Performs comprehensive model analysis\n",
    "\n",
    "    :param feature_importance: DataFrame with feature importance values\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :param clf: Classifier used for prediction\n",
    "    \"\"\"\n",
    "    print(\"=== Model Performance Analysis ===\\n\")\n",
    "\n",
    "    plot_feature_importance(feature_importance)\n",
    "    plot_confusion_matrix_analysis(y_true, y_pred, clf)\n",
    "\n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "    print(f\"\\nOverall Model Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": features,\n",
    "        \"importance\": clf.feature_importances_,\n",
    "    }\n",
    ")\n",
    "feature_importance = feature_importance.sort_values(\"importance\", ascending=False)\n",
    "analyze_model_performance(feature_importance, y_val, y_val_pred, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/model2-11-20s-7f.pkl\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    clf = joblib.load(model_path)\n",
    "else:\n",
    "    print(\n",
    "        f\"Model file not found at {model_path}, uncomment the previous cell to train the model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_to_predict = 1975\n",
    "matchday_to_predict = 18\n",
    "\n",
    "df_predict = df.loc[\n",
    "    (df[\"season\"] == season_to_predict)\n",
    "    & (df[\"matchday\"] == matchday_to_predict)\n",
    "    & (df[\"division\"] == 1)\n",
    "].copy()\n",
    "\n",
    "df_predict = inform_relatives_points(df, df_predict)\n",
    "df_predict = inform_win_lost_index(df, df_predict)\n",
    "df_predict = last5index(df, df_predict)\n",
    "df_predict = last_season_position(df, df_predict)\n",
    "x_predict = df_predict[features]\n",
    "\n",
    "y_predict = clf.predict(x_predict)\n",
    "y_predict = le.inverse_transform(y_predict)\n",
    "df_predict[\"prediction\"] = y_predict\n",
    "df_predict[\"correct\"] = df_predict[\"result\"] == df_predict[\"prediction\"]\n",
    "print(df_predict[\"correct\"].sum() / df_predict.shape[0] * 100)\n",
    "\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_quiniela = df_predict[\n",
    "    [\"season\", \"matchday\", \"home_team\", \"away_team\", \"result\", \"prediction\", \"correct\"]\n",
    "].copy()\n",
    "def quiniela_format(df):\n",
    "    df[\"result\"] = df[\"result\"].map({1: \"1\", 0: \"X\", -1: \"2\"})\n",
    "    df[\"prediction\"] = df[\"prediction\"].map({1: \"1\", 0: \"X\", -1: \"2\"})\n",
    "    return df\n",
    "\n",
    "df_predict_quiniela = quiniela_format(df_predict_quiniela)\n",
    "df_predict_quiniela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
